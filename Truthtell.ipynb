{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxc1V96zmdV8",
        "outputId": "a0212be0-7618-4e71-e62a-2c7485ab42ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tweepy in /usr/local/lib/python3.10/dist-packages (4.14.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: oauthlib<4,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tweepy) (3.2.2)\n",
            "Requirement already satisfied: requests<3,>=2.27.0 in /usr/local/lib/python3.10/dist-packages (from tweepy) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib<2,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from tweepy) (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27.0->tweepy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27.0->tweepy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27.0->tweepy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27.0->tweepy) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install tweepy pandas scikit-learn nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import tweepy\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "BEARER_TOKEN = \"AAAAAAAAAAAAAAAAAAAAADnNxQEAAAAAZKcNIj9AbqPlXTMJq%2BBwyY0Dqxc%3DJXMTTcQRGspFg8V4Z2p22OgJjwTV5d9ZLVhL3WCzjF3Qc80XL2\"  # Replace with your Bearer Token\n",
        "\n",
        "client = tweepy.Client(bearer_token=BEARER_TOKEN)\n",
        "\n",
        "\n",
        "def fetch_tweets(query, max_results=10):\n",
        "    try:\n",
        "        tweets = client.search_recent_tweets(query=query, max_results=max_results, tweet_fields=[\"text\"])\n",
        "        tweet_data = [tweet.text for tweet in tweets.data] if tweets.data else []\n",
        "        return tweet_data\n",
        "    except tweepy.TweepyException as e:\n",
        "        print(f\"Error fetching tweets: {e}\")\n",
        "        return []\n",
        "\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "def preprocess_text(text):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "\n",
        "data = {\n",
        "    \"text\": [\n",
        "        \"Vaccines are harmful and cause autism\",\n",
        "        \"The Earth is not flat; it's a sphere\",\n",
        "        \"COVID-19 is caused by 5G networks\",\n",
        "        \"Climate change is real and caused by human activities\"\n",
        "    ],\n",
        "    \"label\": [1, 0, 1, 0]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "\n",
        "df[\"processed_text\"] = df[\"text\"].apply(preprocess_text)\n",
        "\n",
        "\n",
        "X = df[\"processed_text\"]\n",
        "y = df[\"label\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer()),\n",
        "    ('classifier', MultinomialNB())\n",
        "])\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = pipeline.predict(X_test)\n",
        "print(\"Model Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "\n",
        "def detect_misinformation(tweets):\n",
        "    processed_tweets = [preprocess_text(tweet) for tweet in tweets]\n",
        "    predictions = pipeline.predict(processed_tweets)\n",
        "    results = [{\"tweet\": tweet, \"is_misinformation\": bool(pred)} for tweet, pred in zip(tweets, predictions)]\n",
        "    return results\n",
        "\n",
        "\n",
        "query = \"misinformation lang:en\"\n",
        "tweets = fetch_tweets(query=query, max_results=10)\n",
        "\n",
        "if tweets:\n",
        "    results = detect_misinformation(tweets)\n",
        "    print(\"\\nReal-Time Misinformation Detection Results:\")\n",
        "    for result in results:\n",
        "        status = \"Misinformation\" if result[\"is_misinformation\"] else \"True Information\"\n",
        "        print(f\"- Tweet: {result['tweet']}\\n  Status: {status}\\n\")\n",
        "else:\n",
        "    print(\"No tweets fetched or available for analysis.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P00DZuOJmiDW",
        "outputId": "e42fc767-a3e1-4954-f272-0b1147c0cf51"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.0\n",
            "\n",
            "Real-Time Misinformation Detection Results:\n",
            "- Tweet: RT @ZaleskiLuke: Elon Musk and X Are the Top Misinformation Spreaders Online https://t.co/ii81uz7AbB\n",
            "  Status: Misinformation\n",
            "\n",
            "- Tweet: A video circulating on SM falsely claimed to show a Hindu temple being vandalized in Bangladesh. In reality, the footage dates back to 2021 mob attack on a temple in Pak, spreading misinformation that fuels hatred &amp; worsens religious tensions in Bangladesh\n",
            "https://t.co/9F2wflY9XW\n",
            "  Status: Misinformation\n",
            "\n",
            "- Tweet: Vaccine misinformation distorts science ‚Äì a biochemist explains how RFK Jr. and his lawyer‚Äôs claims threaten public health https://t.co/vAnQ4roqDm via @ConversationUS\n",
            "  Status: Misinformation\n",
            "\n",
            "- Tweet: RT @Jonathan_Elk: As an Israeli-Lebanese Christian, I‚Äôm outraged by the lies coming from the President of Ireland about my country, Israel.‚Ä¶\n",
            "  Status: Misinformation\n",
            "\n",
            "- Tweet: RT @VinceGottalotta: @ZWV134 @CivilLost @KenWali1 @Tomgrif399 @KiltedRef @JeffJun80346519 @8BrianVogel4 @HamRadioJoe @Budleo_Morgan @2457kl‚Ä¶\n",
            "  Status: Misinformation\n",
            "\n",
            "- Tweet: You know the world is doomed when people who actively correct misinformation on this platform are being slandered with fake screenshots. It's a slippery dystopian slope that we're falling into. https://t.co/cVn8Ji2tBQ\n",
            "  Status: Misinformation\n",
            "\n",
            "- Tweet: RT @SHABAZGIL: Shame on @geonews_urdu for spreading hate &amp; misinformation! First, on the behest of the Pakistani military establishment, Ge‚Ä¶\n",
            "  Status: Misinformation\n",
            "\n",
            "- Tweet: @dr_andrealove I don't profit from it. I am just helping people overwhelmed with the amount of misinformation about it:\n",
            "\n",
            "DM me if you want the doccie from the professor that lead the research.\n",
            "\n",
            "Also I am interested in all independent research on the topic, it is turning out to be the best way‚Ä¶ https://t.co/vAkBUzfYGs https://t.co/9K5gPc2OO7\n",
            "  Status: Misinformation\n",
            "\n",
            "- Tweet: RT @DschlopesIsBack: The FDA is one of the greatest sources of Covid misinformation in the entire world. https://t.co/wbZfKqkF7y\n",
            "  Status: Misinformation\n",
            "\n",
            "- Tweet: Hey @_kaitoai, do you have any measure in place to address misinformation and unethical engagement farming? üòè\n",
            "\n",
            "There's been an influx of large accounts spreading false information about $XION. They're claiming that @burnt_xion is rewarding EVERYONE in the top 100 with 1,000‚Ä¶ https://t.co/NC0m6qD7pH https://t.co/pDRKzLXmMZ\n",
            "  Status: Misinformation\n",
            "\n"
          ]
        }
      ]
    }
  ]
}